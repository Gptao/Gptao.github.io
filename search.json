[{"title":"VRPSAM--SAM with Visual Reference Prompt","url":"/2024/03/18/VRP-SAM-CVPR2024/","content":"\n# [VRP-SAM: SAM with Visual Reference Prompt](https://arxiv.org/pdf/2402.17726)\n<center><img width=\"90%\" src=\"VRP-SAM-CVPR2024/image-2.png\" /></center>\n## 解决问题\nEmpowers the Segment Anything Model (SAM) to utilize annotated reference images as prompts for segmentation.\n\nVisual reference segmentation with minimal learnable parameters and strong generalization capabilities.\n\n## 提出方法\n\n<center><img width=\"90%\" src=\"VRP-SAM-CVPR2024/image.png\" /></center>\n<center>VRPSAM 接受point, scribble, box或者mask标注好的参考图像 </center>\n\n<center><img width=\"90%\" src=\"VRP-SAM-CVPR2024/image-1.png\" /></center>\n\n<center>Visual reference Prompt Encoder包括Feature Augmenter和Prompt Generator</center>\n\n<br>\nFeature Augmenter中 Image encoder是固定的ResNet50, 使用reference的MaskAvgPool特征和前景mask作为提示, Prompt Generator 使用N个VRP quries首先和参考图像做交互学习分割目标知识，然后和目标图像做交互获得前景信息，最后经SA得到和SAM对齐的Prompts（听上去很玄乎）\n\n## 方法细节\n二分类损失和Dice Loss作为损失函数:\n<center><img width=\"40%\" src=\"VRP-SAM-CVPR2024/image-3.png\" /></center>\n<br>\n实验设置： \n- Few-shot setting on COCO-20<sup>i</sup>（60 train base+20 test novel） and Pascal-5<sup>i</sup> datasets(15 train base+5 test novel), randomly sampled 1000 reference-target pairs in each fold for evaluation.\n- 使用SEEM生成point, cribble和box annotations.\n\n## 实验结果\n![](VRP-SAM-CVPR2024/image-4.png)\n<center><img width=\"90%\" src=\"VRP-SAM-CVPR2024/image-5.png\" /></center>\n\n","tags":["CVPR2024"]}]